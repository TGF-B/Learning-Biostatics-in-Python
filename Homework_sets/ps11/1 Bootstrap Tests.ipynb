{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "markdown",
                    "checksum": "e57dd1e6a2040a95cd5c6c204aba6bfe",
                    "grade": false,
                    "grade_id": "cell-ee72b40b0bbd6952",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "source": [
                "# Question 1: Bootstrap Hypothesis Testing\n",
                "\n",
                "We will use the tools developed in the previous question to perform basic bootstrap hypothesis testing. First, paste your definitions of `p_value`, `resample`, `mean_difference`, `t_stat` and `F_stat` from Question 0 below. (Two helper functions, `sum_of_squares` and a numpy-ified `shift_mean`, which returns a dataset shifted such that its mean is the specifed value, are provided for you.)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "nbgrader": {
                    "cell_type": "code",
                    "checksum": "5a74bed373c884761d3f2af590d3dd0e",
                    "grade": false,
                    "grade_id": "cell-ce1ee7367f9bf557",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true
                }
            },
            "outputs": [],
            "source": [
                "import numpy\n",
                "\n",
                "def shift_mean(data, new_mean):\n",
                "    data = numpy.asarray(data)\n",
                "    mean = numpy.mean(data)\n",
                "    shift_factor = new_mean - mean\n",
                "    return data + shift_factor\n",
                "\n",
                "def sum_of_squares(data, reference):\n",
                "    data = numpy.asarray(data)\n",
                "    return numpy.sum((data - reference)**2)\n",
                "\n",
                "### YOUR CODE BELOW:\n",
                "\n",
                "def p_value(actual_stat, resampled_stats, null_hyp_stat=0, two_tailed=True):\n",
                "    resampled_stats = numpy.asarray(resampled_stats)\n",
                "    # YOUR ANSWER HERE\n",
                "    \n",
                "def resample(data_sets, statistic, n_resamples):\n",
                "    # turn every dataset in `data_sets` into a `numpy` array \n",
                "    data_sets = [numpy.asarray(data) for data in data_sets]\n",
                "    # YOUR ANSWER HERE\n",
                "\n",
                "def mean_difference(data1, data2):\n",
                "    # YOUR ANSWER HERE\n",
                "\n",
                "def t_stat(data1, data2):\n",
                "    # YOUR ANSWER HERE\n",
                "\n",
                "def F_stat(*data_sets):\n",
                "    # YOUR ANSWER HERE\n",
                "    return ss_between / ss_within"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "markdown",
                    "checksum": "b8e8e8e0080b581fc175b214649eb6d9",
                    "grade": false,
                    "grade_id": "cell-443048f52537aca7",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "source": [
                "## Question 1.1\n",
                "\n",
                "Now, let's read in some data. The file \"bloodpressure.txt\" contains a number of lines, each with a measured blood pressure and a genotype at a particular SNP specified as \"AA\" or \"GG\". The values are separated by a tab character (spelled `'\\t'` in Python). Note that there *is* a header row. (Open the file in the Jupyter file browser to see. Note that the browser helpfully shows the tab characters as distinct from spaces...)\n",
                "\n",
                "Read in the file, and store the \"AA\" blood pressures (converted to floating-point numbers) in a list named `aa_bp` and the \"GG\" blood pressures in a list named `gg_bp`. Last, convert each list to a numpy array."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "nbgrader": {
                    "cell_type": "code",
                    "checksum": "089e27175ae2cfc3f3295c93e8d16a2e",
                    "grade": false,
                    "grade_id": "cell-dcc8e885214da27e",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true
                }
            },
            "outputs": [],
            "source": [
                "# YOUR ANSWER HERE\n",
                "\n",
                "print(len(aa_bp), len(gg_bp))\n",
                "print(numpy.mean(aa_bp), numpy.mean(gg_bp))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "code",
                    "checksum": "5cffb39754ff1db299d45997bbb018ae",
                    "grade": true,
                    "grade_id": "cell-55ab199b0e19aed8",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "assert len(aa_bp) == 56\n",
                "assert len(gg_bp) == 205\n",
                "assert type(aa_bp) is numpy.ndarray\n",
                "assert abs(numpy.mean(gg_bp) - 124.021365854) < 0.00000001"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "markdown",
                    "checksum": "d4e9cfc99d8302903b0f00ba3f32cc6b",
                    "grade": false,
                    "grade_id": "cell-819367da9359ceb3",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "source": [
                "Below, we plot the GG and AA data. Note several useful features of plot:\n",
                "  1. By changing `plt.rcParams['figure.figsize']`, we can make the default figure size a little larger, which helps readability.\n",
                "  2. the `density=True` parameter changes the histogram from using raw data counts to presenting the fraction of the data in each bin. This is handy for datasets with different total sizes, such as these.\n",
                "  3. It's convenient to plot both histograms on the same set of bins. To ensure this happens, we collect the bin boundaries that are automatically calculated from the GG data, and use those as the boundaries for the AA histogram. (Read the documentation for `plt.hist` and it will tell you that the `bins` parameter can be a number, 'auto', or a list of bin boundaries. Moreover, the documentation will tell you that `plt.hist` provides the bin boundaries used as the second element in the returned values.)\n",
                "  4. Note how to provide labels and legends.\n",
                "  5. Note the use of the `alpha=0.5` parameter to turn the AA histogram 50% transparent.\n",
                "  \n",
                "Also, looking at the plot, do the AA and GG data seem particularly distinguishable? Make a guess as to whether the difference will be statistically significant."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "code",
                    "checksum": "6d24b49cd526e35e61ce098b3148bb38",
                    "grade": false,
                    "grade_id": "cell-ba81264d8e12223a",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "%matplotlib inline\n",
                "import matplotlib.pyplot as plt\n",
                "plt.style.use('ggplot')\n",
                "plt.rcParams['figure.figsize'] = [12, 4]\n",
                "\n",
                "gg_mean = numpy.mean(gg_bp)\n",
                "aa_mean = numpy.mean(aa_bp)\n",
                "hist_data = plt.hist(gg_bp, bins='auto', density=True, label='GG')\n",
                "plt.axvline(gg_mean, color='orange', label='GG mean')\n",
                "bin_edges = hist_data[1]\n",
                "hist_data = plt.hist(aa_bp, bins=bin_edges, density=True, alpha=0.5, label='AA')\n",
                "plt.axvline(aa_mean, color='blue', label='AA mean')\n",
                "legend = plt.legend()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "markdown",
                    "checksum": "a30d917d79736d5f50354ed39869b1e3",
                    "grade": false,
                    "grade_id": "cell-30194bb258c0dde0",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "source": [
                "## Question 1.2\n",
                "Let's ask if the difference in blood pressure between these groups is statistically significant. \n",
                "\n",
                "First, write a function to calculate a bootstrapped p-value to test the hypothesis that the means of two groups are different. Since the null hypothesis is that the means are the same, make sure to resample under this assumption. Let the user provide a statistic function to score how different the means are (i.e. `mean_difference` or `t_stat` or `F_stat`). This function should calculate the actual statistic, then shift each data group so that its mean is equal to the grand mean (the mean of all the data concatenated together). The `shift_mean` function defined above may help.\n",
                "\n",
                "Next, the function should generate a set of resampled statistics of the shifted data (which comply with the null hypothesis that each data set has an identical mean), and calculate a p-value therefrom. The function should return the actual statistic, the list of statistics calculated from the resamples under the null hypothesis, and the p-value.\n",
                "\n",
                "The histogram plotted below shows in red the null distribution (the values of the statistic you might expect by chance when the means are actually the same), and the blue line shows the value of the actual statistic we obtained. The further out on the tail of the histogram the blue line is, the lower the p-value."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "nbgrader": {
                    "cell_type": "code",
                    "checksum": "b072aca4ee0a0c756a505e05c0a19cb8",
                    "grade": false,
                    "grade_id": "cell-e8796c991d2e8003",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true
                }
            },
            "outputs": [],
            "source": [
                "def bootstrap_means_different(data1, data2, statistic, n_resamples=10000):\n",
                "    # YOUR ANSWER HERE\n",
                "    return actual_stat, resampled_stats, p\n",
                "\n",
                "actual_diff, resampled_diffs, mean_diff_p = bootstrap_means_different(aa_bp, gg_bp, mean_difference)\n",
                "plt.hist(resampled_diffs, bins='auto')\n",
                "plt.axvline(actual_diff, color='blue')\n",
                "print(actual_diff, mean_diff_p)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "code",
                    "checksum": "c2898f89b2b8e871e1e3865ada55734e",
                    "grade": true,
                    "grade_id": "cell-90baa29994718b33",
                    "locked": true,
                    "points": 3,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "stat, samples, p = bootstrap_means_different(aa_bp, gg_bp, mean_difference)\n",
                "assert len(samples) == 10000\n",
                "assert abs(stat + 5.25058013937) < 0.000001\n",
                "assert 0.021 < p < 0.029\n",
                "\n",
                "stat, samples, p = bootstrap_means_different(aa_bp, gg_bp - 3, mean_difference)\n",
                "assert len(samples) == 10000\n",
                "assert abs(stat + 2.25058013937) < 0.000001\n",
                "assert 0.32 < p < 0.36"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "markdown",
                    "checksum": "10a3a0bee61d212f6f45b0ac6b743a01",
                    "grade": false,
                    "grade_id": "cell-66915006e3701fcd",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "source": [
                "In class I mentioned that the correction for sample variance is a critical feature of the t-statistic for parametric statistics: for a given difference in the means, datasets with large standard deviations are harder to distinguish from one another than datasets with small standard deivations.\n",
                "\n",
                "Does this matter here? Generate 200 p-values from the AA and GG data using the `mean_difference` statistic and 200 using the `t_stat` statistic. (Use `n_resamples=500` to make this not take forever...) Plot superimposed histograms of these p-values just as above (though don't bother with vertical lines showing the \"mean p-value\"). How different do these histograms appear?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "nbgrader": {
                    "cell_type": "code",
                    "checksum": "e6fb175d231b331e2539c4157f21fe65",
                    "grade": false,
                    "grade_id": "cell-73d5dc7509d41737",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true
                }
            },
            "outputs": [],
            "source": [
                "mean_diff_ps = []\n",
                "t_stat_ps = []\n",
                "\n",
                "# YOUR ANSWER HERE\n",
                "print('Average p-value with mean differences:', numpy.mean(mean_diff_ps))\n",
                "print('Average p-value with t-statistic:', numpy.mean(t_stat_ps))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "code",
                    "checksum": "0079f0214550fed48d98d603b2fadf22",
                    "grade": true,
                    "grade_id": "cell-e33432bd997ba350",
                    "locked": true,
                    "points": 3,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "assert numpy.mean(mean_diff_ps) < numpy.mean(t_stat_ps)\n",
                "assert len(mean_diff_ps) == 200"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "markdown",
                    "checksum": "782589bfa167562dd53a82bd9f9d2dca",
                    "grade": false,
                    "grade_id": "cell-c0be6f49641e15f4",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "source": [
                "From this, you should be able to see that the t-statistic produces a sligtly more conservative test (i.e. larger p-values). Because it (sensibly) takes into account the spread in the data, the t-statistic will generally judge these datasets to be less different than the difference in means alone. \n",
                "\n",
                "## Question 1.3\n",
                "\n",
                "From the histograms of the blood pressure data, there may be a few outliers. Write a new statistic to compare the differences in median (using `numpy.median`), and compute the p-value for this test of medians. You can't just use your `bootstrap_means_different` function above, because that resamples under the null hypothesis of equal means, not equal medians. So write new functions for `bootstrap_medians_different` and `shift_median`. Note that unlike `bootstrap_means_different` which took a `statistic` function (allowing us to compare the t-test's way of scoring the difference between means to the simpler way of just subtracting the means), `bootstrap_medians_different` will only ever use `median_difference`, so you can just code that in directly."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "nbgrader": {
                    "cell_type": "code",
                    "checksum": "365d0ae46ca8a216997635997e92ab2f",
                    "grade": false,
                    "grade_id": "cell-25494ad5923a5870",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true
                }
            },
            "outputs": [],
            "source": [
                "def median_difference(data1, data2):\n",
                "    # YOUR ANSWER HERE\n",
                "\n",
                "def shift_median(data, new_median):\n",
                "    # YOUR ANSWER HERE\n",
                "\n",
                "# below should print 42 (or something arbitrarily close to it), to prove that shifting to the specified median works...\n",
                "print(numpy.median(shift_median(aa_bp, 42)))\n",
                "    \n",
                "def bootstrap_medians_different(data1, data2, n_resamples=10000):\n",
                "    # YOUR ANSWER HERE\n",
                "    return actual_stat, resampled_stats, p\n",
                "\n",
                "actual_diff, resampled_diffs, median_diff_p = bootstrap_medians_different(aa_bp, gg_bp)\n",
                "plt.hist(resampled_diffs, bins='auto')\n",
                "plt.axvline(actual_diff, color='blue')\n",
                "print(actual_diff, median_diff_p)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "code",
                    "checksum": "9aca828d6567e78421ac529e3d26b6d4",
                    "grade": true,
                    "grade_id": "cell-45f078c8e4e5a254",
                    "locked": true,
                    "points": 6,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "assert abs(numpy.median(shift_median(aa_bp, 42)) - 42) < 0.0000001\n",
                "assert 0.41 < median_diff_p < 0.46"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "markdown",
                    "checksum": "419ad0e859e54c53717c0ecba5aff7b6",
                    "grade": false,
                    "grade_id": "cell-cade95c751754e85",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "source": [
                "Interesting! Even though there were clearly significant differences in the mean (either by the mean-differences method or the t-statistic), there is no significant difference in the median blood pressure between the genotypes! This means that the differences observed may be more due to outliers than the position of most of the individuals in the datasets.\n",
                "\n",
                "Note that this doesn't mean that there are no real biological differences in the AA or GG genotypes! It just means that those differences mostly manifest in a few extreme individuals of each genotype. This is critical information for understanding the biology of these differences. (e.g. perhaps this indicates that there is some other, relatively rare interacting allele that potentiates the effect of the AA or GG genotype? Or perhaps there is some gene-by-environment interaction driven by an environment that only a few individuals in the population experience...)\n",
                "\n",
                "## Question 1.4\n",
                "\n",
                "So far we have been examining questions about the location of the data (means or medians, or even in the last homework, the minimum). What about the scale of the data? Do the datasets under consideration have equal variance? Or is there more variability in one dataset than the other?\n",
                "\n",
                "Let's start by defining a statistic. For the hypothesis that the means were not the same, our statistic was the difference between means. However, standard deviation is a measure of *scale*, not position, and typically we think of scales as a multiplicative factor. So instead of looking at the difference in the standard deviations, let's look at the *ratio* of the standard deviations of the two datasets. The null hypothesis in this case will be that the ratio is 1.\n",
                "\n",
                "Now, how should we sample under this null hypothesis of equal standard deviations? To modify the standard deviation of a dataset without changing its mean, you need to first shift it to have zero mean, then multiply the dataset by whatever scaling factor is desired, and then shift back to the original mean. (Note: if a dataset has a standard deviation of 3 and you want it to have a standard deviation of 6, the scaling factor to multiply by is 2.)\n",
                "\n",
                "So first write an `equalize_stds` function that calculates a grand standard deviation of the concatenated data and rescales the each individual data set such that they all have that same standard deviation. Then write a `std_ratio` function to return the ratio of standard deviations (using `numpy.std`). \n",
                "\n",
                "Now, the null hypothesis of equal standard deviations means that we expect the \"true\" ratio of standard deviations to be 1. To calculate a two-tailed p-value, we need to count the number of times that the resampled data (which were forced to comply with that null hypothesis) produces a ratio of standard deviations farther -- in either direction -- from the null-hypothesis value of 1 than the actual standard deviation ratio is. \n",
                "\n",
                "The current `p_value` function uses subtraction to define the distance between the statistic and the null hypothesis, but this doesn't make sense for ratios. If we observe a ratio of 3 and the null hypothesis is that the ratio is 1, a ratio similarly extreme in the other direction is not -1 (two units less than than 1), it is 1/3 (three times smaller than 1). That is, you need to measure distance multiplicatively, not additively.\n",
                "\n",
                "So, you will need to write a new `p_value_ratio` function that calculates whether a resampled ratio or the actual ratio is multiplicatively farther from 1. The bookkeeping for doing this in all possible cases winds up getting complex fast, though. Previously we avoided similar bookkeeping by taking the absolute value of the distance between a statistic and the null hypothesis, so we could just ask if a resample was g. The multaplicative equivalent is to make sure that a ratio is always >= 1 by taking the reciprocal if the ratio is less than one. \n",
                "\n",
                "As such, you should reciprocate all the ratios (both the resampled ones and the actual one) if they are < 1. Then, since all of the ratios are by construction >= 1, it becomes quite easy to see whether a resampled ratio is more extreme than the actual one.\n",
                "\n",
                "\n",
                "Last, write a function `bootstrap_std_difference` that brings all of these together to calculate a p-value. No need for this function to take a user-specified statistic function; it will always use `std_ratio`.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "nbgrader": {
                    "cell_type": "code",
                    "checksum": "4f8e3a75c6ea88d76dd86b099c96e0e5",
                    "grade": false,
                    "grade_id": "cell-b2d014aaa83b9b54",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true
                }
            },
            "outputs": [],
            "source": [
                "def equalize_stds(data1, data2):\n",
                "    # YOUR ANSWER HERE\n",
                "    return equalized1, equalized2\n",
                "\n",
                "eq_aa, eq_gg = equalize_stds(aa_bp, gg_bp)\n",
                "print(numpy.std(eq_aa), numpy.std(eq_gg))\n",
                "    \n",
                "def std_ratio(data1, data2):\n",
                "    # YOUR ANSWER HERE\n",
                "\n",
                "\n",
                "def p_value_ratio(actual_ratio, resampled_ratios):\n",
                "    # Since this is a two-tailed test, we don't care if the actual or resampled ratios\n",
                "    # are larger or smaller than 1, but just by what factor they are larger or smaller.\n",
                "    # So we will just convert all ratios to be larger than 1 and compare for \n",
                "    # extreme-ness only in one direction. (This is akin to taking absolute values\n",
                "    # in the previous p-value calculation.)\n",
                "    \n",
                "    # Sometimes a for-loop is the easiest way to do things, even when numpy is\n",
                "    # available. So make a new version of resampled_ratios using a for-loop,\n",
                "    # where every value < 1 is replaced by its reciprocal.\n",
                "    # Also don't forget to make sure actual_ratio is > 1 also...\n",
                "    # YOUR ANSWER HERE\n",
                "    \n",
                "def bootstrap_std_different(data1, data2, n_resamples=10000):\n",
                "    # YOUR ANSWER HERE\n",
                "    return actual_ratio, resampled_ratios, p_val\n",
                "\n",
                "ratio, resampled_ratios, std_ratio_p = bootstrap_std_different(gg_bp, aa_bp)\n",
                "plt.hist(resampled_ratios, bins='auto')\n",
                "plt.axvline(ratio, color='blue')\n",
                "print(ratio, std_ratio_p)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "code",
                    "checksum": "6489af4785624436a112a3e3c1d9d6ae",
                    "grade": true,
                    "grade_id": "cell-f0120b0bad6ae86e",
                    "locked": true,
                    "points": 8,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "assert abs(numpy.std(eq_aa) - 13.642075681) < 0.000001\n",
                "assert abs(numpy.std(eq_aa) - numpy.std(eq_gg)) < 0.000001\n",
                "assert abs(numpy.mean(aa_bp) - numpy.mean(eq_aa)) < 0.000001\n",
                "\n",
                "assert std_ratio([0, 4, 8], [1, 2, 3]) == 1/std_ratio([1, 2, 3], [0, 4, 8])\n",
                "assert std_ratio([0, 4, 8], [1, 2, 3]) == 4\n",
                "\n",
                "assert p_value_ratio(1/4, [1/5, 1/4, 1/2, 2, 4, 5, 6]) == 5/7\n",
                "assert 0.023 < std_ratio_p < 0.031"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "markdown",
                    "checksum": "7053186139328a8471a745a195299dfc",
                    "grade": false,
                    "grade_id": "cell-9eb1869e3f0b903a",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "source": [
                "So, the AA data is significantly more spread out than the GG data (the GG/AA standard deviation ratio is around 0.77). That is, it was rare to see a ratio so different from 1 when we resampled data that had identical standard deviations.\n",
                "\n",
                "## Question 1.5\n",
                "\n",
                "Last, we haven't done an ANOVA test yet to see if three or more samples have different means. Imagine that we are testing a novel protocol to differentiate iPS cells into pancreatic beta cells. We have tried four different doses of a drug, and it looks like maybe one or two of those doses had an effect on the differentiation efficiency. But the data were very noisy, so we want to know whether the effect is likely just due to the variability within each replicate.\n",
                "\n",
                "Write a function, `bootstrap_anova`, that takes an arbitrary number of datasets, shifts them each to the grand mean, and then resamples them to estimate the distribution of F-statistics under null hypothesis of no difference in means.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "nbgrader": {
                    "cell_type": "code",
                    "checksum": "94fc48d7e89462ba1d7da5a3f970d944",
                    "grade": false,
                    "grade_id": "cell-e8a4a50f39733b84",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true
                }
            },
            "outputs": [],
            "source": [
                "dose0 = numpy.array([\n",
                "        0.44353122,  0.01012966,  0.28873548,  0.41508564,  0.63920005,\n",
                "        0.38840745,  0.56994441,  0.39461312,  0.63531554,  0.2243476 ,\n",
                "        0.0146331 ,  0.34027282,  0.11461404,  0.3706856 ,  0.03022053,\n",
                "        0.26903881,  0.40752708,  0.57226634,  0.56036688,  0.45346642,\n",
                "        0.24393661,  0.11314218,  0.37424453,  0.02731236,  0.36170049,\n",
                "        0.28624436,  0.27673137,  0.02059751,  0.33590967,  0.34159704])\n",
                "\n",
                "dose1 = numpy.array([\n",
                "        0.40447368,  0.04894949,  0.43691414,  0.36156942,  0.55082948,\n",
                "        0.45234243,  0.08263355,  0.53735037,  0.19556559,  0.14684213,\n",
                "        0.12670269,  0.09968791,  0.09903378,  0.23750902,  0.30392521,\n",
                "        0.27720465,  0.64437095,  0.62903639,  0.62678483,  0.41837535,\n",
                "        0.02564389,  0.34572511,  0.48980329,  0.67060822,  0.40915237,\n",
                "        0.67581135,  0.63069843,  0.1503978 ,  0.12660994,  0.25990044])\n",
                "\n",
                "dose2 = numpy.array([\n",
                "        0.2023481 ,  0.17263792,  0.24061181,  0.23310464,  0.75607685,\n",
                "        0.67992754,  0.1684292 ,  0.72103724,  0.50828973,  0.19148194,\n",
                "        0.76176207,  0.31807931,  0.04664898,  0.22524644,  0.83347876,\n",
                "        0.58708986,  0.40128552,  0.33489851,  0.16898191,  0.0937998 ,\n",
                "        0.82937534,  0.69083288,  0.14723692,  0.51264047,  0.46377266,\n",
                "        0.55422885,  0.49082234,  0.80979359,  0.43772453,  0.35936454])\n",
                "\n",
                "dose3 = numpy.array([\n",
                "        0.56307295,  0.260053  ,  0.65498897,  0.4074656 ,  0.38936101,\n",
                "        0.10776682,  0.46990373,  0.39733009,  0.04181612,  0.15412012,\n",
                "        0.44600949,  0.56160325,  0.09421104,  0.29194078,  0.69317676,\n",
                "        0.22814752,  0.17328897,  0.40468055,  0.69985375,  0.39791401,\n",
                "        0.55387151,  0.68740186,  0.52072545,  0.65457568,  0.19796182,\n",
                "        0.58060724,  0.6489602 ,  0.2342047 ,  0.42521541,  0.62100328])\n",
                "\n",
                "plt.scatter([0]*30, dose0)\n",
                "plt.scatter([1]*30, dose1)\n",
                "plt.scatter([2]*30, dose2)\n",
                "plt.scatter([3]*30, dose3)\n",
                "\n",
                "def bootstrap_anova(*data_sets, n_resamples=10000):\n",
                "    # YOUR ANSWER HERE\n",
                "    return actual_stat, resampled_stats, p_val\n",
                "\n",
                "f_value, resampled_f_values, anova_p = bootstrap_anova(dose0, dose1, dose2, dose3)\n",
                "plt.figure()\n",
                "plt.hist(resampled_f_values, bins='auto')\n",
                "plt.axvline(f_value, color='blue')\n",
                "print(f_value, anova_p)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "code",
                    "checksum": "a9af57614fc598618b3054c8ad48ea1f",
                    "grade": true,
                    "grade_id": "cell-accbe45cf1c97766",
                    "locked": true,
                    "points": 5,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "assert abs(f_value - 0.0519515028907) < 0.000001\n",
                "assert 0.11 < anova_p < 0.13"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "markdown",
                    "checksum": "df29a24923ee7b337e3e80fdd3e816e2",
                    "grade": false,
                    "grade_id": "cell-cdba568c6d2b682c",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "source": [
                "It appears that the blip in the data for dose 2 was just that: a blip. Maybe with a larger dataset, that dose would really have a higher differentiation efficiency... or maybe not."
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}