{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "markdown",
                    "checksum": "5d8e744f3698e4d313ea9b1fbb71ddbb",
                    "grade": false,
                    "grade_id": "cell-826f40099ad2f80c",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "source": [
                "# Question 2: Standard Error of the Mean\n",
                "\n",
                "In this question, we will use resampling to examine how broadly the *means* of samples from the same population are distributed.\n",
                "\n",
                "First, load up the blood pressure data as before, but this time use the `bloodpressure2.txt` file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "nbgrader": {
                    "cell_type": "code",
                    "checksum": "79d260a89d67ed4a5985931b6fe0ece1",
                    "grade": false,
                    "grade_id": "cell-42aae33abf90cb64",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true
                }
            },
            "outputs": [],
            "source": [
                "import numpy\n",
                "\n",
                "# YOUR ANSWER HERE\n",
                "\n",
                "print(len(aa_bp), len(gg_bp))\n",
                "print(numpy.mean(aa_bp), numpy.mean(gg_bp))\n",
                "\n",
                "%matplotlib inline\n",
                "import matplotlib.pyplot as plt\n",
                "plt.style.use('ggplot')\n",
                "plt.rcParams['figure.figsize'] = [12, 4]\n",
                "\n",
                "gg_mean = numpy.mean(gg_bp)\n",
                "aa_mean = numpy.mean(aa_bp)\n",
                "hist_data = plt.hist(gg_bp, bins='auto', density=True, label='GG')\n",
                "plt.axvline(gg_mean, color='orange', label='GG mean')\n",
                "bin_edges = hist_data[1]\n",
                "hist_data = plt.hist(aa_bp, bins=bin_edges, density=True, alpha=0.5, label='AA')\n",
                "plt.axvline(aa_mean, color='blue', label='AA mean')\n",
                "legend = plt.legend()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "markdown",
                    "checksum": "d295e5947fb2d05ae556b472600c8d2b",
                    "grade": false,
                    "grade_id": "cell-c6e303ebfa2dd51e",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "source": [
                "## Question 2.1\n",
                "Write a function called `resample_means` that will repeatedly resample a given dataset and return a list of the means of each of those resamples.\n",
                "\n",
                "Then generate means from 10000 resamples of the GG dataset and plot a histogram of those means, overlaid transparently atop of the original GG dataset (use `bins='auto'` and `density=True` for both histograms.)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "nbgrader": {
                    "cell_type": "code",
                    "checksum": "3b54f844c772569067f095f792de3555",
                    "grade": false,
                    "grade_id": "cell-f781a9c76921ec0b",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true
                }
            },
            "outputs": [],
            "source": [
                "def resample_means(data, n_resamples=10000):\n",
                "    # YOUR ANSWER HERE\n",
                "\n",
                "gg_means = resample_means(gg_bp)\n",
                "# YOUR ANSWER HERE\n",
                "print(numpy.mean(gg_bp), numpy.mean(gg_means))\n",
                "print(numpy.std(gg_bp), numpy.std(gg_means))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "code",
                    "checksum": "521b694d098fb270d2a7ec5c002e4b97",
                    "grade": true,
                    "grade_id": "cell-48505925c273fbcb",
                    "locked": true,
                    "points": 2,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "assert len(gg_means) == 10000\n",
                "assert 1.20 < numpy.std(gg_means) < 1.26"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "markdown",
                    "checksum": "3b0f4eae2236fcef9932403197739397",
                    "grade": false,
                    "grade_id": "cell-18f20b5c930e6ce6",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "source": [
                "While the GG blood pressure data has a pretty wide spread (standard deviation of 17.7), the means of repeated resamples are very narrowly clustered around the mean of the GG data. \n",
                "\n",
                "As we discussed in class, the *standard deviation* of a statistic (such as the mean) upon repeated sampling is called the \"standard error\" of that statistic. So here, the standard error of the mean is \u00b11.23 or so.\n",
                "\n",
                "## Question 2.2\n",
                "Repeat the above for the AA dataset:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "nbgrader": {
                    "cell_type": "code",
                    "checksum": "d785285c56e413f5814de6b9f7eaa450",
                    "grade": false,
                    "grade_id": "cell-6335119d9d7c4263",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true
                }
            },
            "outputs": [],
            "source": [
                "# YOUR ANSWER HERE\n",
                "print(numpy.mean(aa_bp), numpy.mean(aa_means))\n",
                "print(numpy.std(aa_bp), numpy.std(aa_means))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "code",
                    "checksum": "566c3abe3be827c5f0058769e383331a",
                    "grade": true,
                    "grade_id": "cell-6849ca1c05a88745",
                    "locked": true,
                    "points": 2,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "assert len(aa_means) == 10000\n",
                "assert 2.10 < numpy.std(aa_means) < 2.21"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "markdown",
                    "checksum": "2c001d43ca188771448afd358fadfcbb",
                    "grade": false,
                    "grade_id": "cell-511fb439ce4757a5",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "source": [
                "While the standard deviation of the AA dataset is slightly smaller than that of the GG dataset, the standard error is almost double in size! What's going on?\n",
                "\n",
                "One hint is that the AA dataset is much smaller (56 measurements, versus 205 for the GG data). Maybe there's a relationship between sample size and how accurately the mean can be measured...\n",
                "\n",
                "## Question 2.3\n",
                "To examine this relationship, we will need to pretend that we have a dataset of different sizes. So we are going to depart briefly from the usual resampling strategy of drawing exactly the same number of points as our original dataset. Modify `resample_means` to take a `sample_size` parameter. Then, calculate the standard error of the mean of the GG data for each of the specified sample sizes. Use the default 10000 resamples. The code below will plot this relationship."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "nbgrader": {
                    "cell_type": "code",
                    "checksum": "fbc61c8234a8c0ef59b4433d309670bd",
                    "grade": false,
                    "grade_id": "cell-087558f62dd77ce2",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true
                }
            },
            "outputs": [],
            "source": [
                "def resample_means_of_size(data, sample_size, n_resamples=10000):\n",
                "    # YOUR ANSWER HERE\n",
                "\n",
                "sample_sizes = [10, 20, 40, 80, 160, 320]\n",
                "standard_errors = []\n",
                "# YOUR ANSWER HERE\n",
                "plt.plot(sample_sizes, standard_errors)\n",
                "plt.xlabel('sample size')\n",
                "plt.ylabel('standard error')\n",
                "print(standard_errors)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "markdown",
                    "checksum": "0914be3666207222c8c7557a2f9f375c",
                    "grade": false,
                    "grade_id": "cell-fd9538bc9eec2c61",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "source": [
                "## Question 2.4\n",
                "So, what is the relationship between the standard error and the sample size? Specifically, to decrease the error by half (from 4 to 2, say, or from 2 to 1), what factor do you have to increase the sample size by? What about to decrease error by 4-fold (from 4 to 1)?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "nbgrader": {
                    "cell_type": "markdown",
                    "checksum": "7c8b23132e32a6d0e4d030711583f4ae",
                    "grade": true,
                    "grade_id": "cell-3ad058adc1da771b",
                    "locked": false,
                    "points": 2,
                    "schema_version": 3,
                    "solution": true
                }
            },
            "source": [
                "YOUR ANSWER HERE"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "markdown",
                    "checksum": "23dc390897be7047a453c2c696d40b75",
                    "grade": false,
                    "grade_id": "cell-afc759ffbd22166b",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "source": [
                "A little thinking about the above answer will tell you that this means that the sample size is inversely proportional to the square of the standard error of the mean. For compactness, we'll call the sample size 'n' and the standard error of the mean 'SEM'. Thus:\n",
                "\n",
                "$\\textit{n} \\propto 1/\\textit{SEM}^2$ (where $\\propto$ means \"is proportional to\").\n",
                "\n",
                "Rearranging, we have $\\textit{SEM} \\propto \\frac{1}{\\sqrt{\\textit{n}}}$. Or equivalently, \n",
                "$\\textit{SEM} = \\frac{p}{\\sqrt{\\textit{n}}}$\n",
                "for some constant of proportionality $p$.\n",
                "\n",
                "In other words, $p = \\textit{SEM} \\cdot \\sqrt{\\textit{n}}$\n",
                "\n",
                "Let's calculate this constant, for each of the SEM / sample-size pairs we calculated above. That is, make a list `ps` containing the value of $\\textit{SEM} \\cdot \\sqrt{\\textit{n}}$ for each sample size and standard error that you calculated above. (Use a for loop...) And recall that `x**2` squares something in Python, while `x**0.5` takes the square root..."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "nbgrader": {
                    "cell_type": "code",
                    "checksum": "b34562f806a65710e7771753aa529c86",
                    "grade": false,
                    "grade_id": "cell-e5752ce4dafa132e",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true
                }
            },
            "outputs": [],
            "source": [
                "ps = []\n",
                "# YOUR ANSWER HERE\n",
                "print(ps)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "code",
                    "checksum": "4be4de6d5cfe75bc860ae5889516f74d",
                    "grade": true,
                    "grade_id": "cell-0cf572fd11cc1d5e",
                    "locked": true,
                    "points": 2,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "assert len(ps) == len(sample_sizes)\n",
                "for p in ps:\n",
                "    assert 16.5 < p < 18.5"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "markdown",
                    "checksum": "d8bdd8fedf7c9982f0f628406fbf7f49",
                    "grade": false,
                    "grade_id": "cell-c65510b63caa988d",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "source": [
                "If everything went right, you should have gotten basically the same constant for each pair. What does the constant of proportionality we got mean?\n",
                "\n",
                "Specifically, the numbers should be right around 17.7... what property of the GG data is right around that number?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "nbgrader": {
                    "cell_type": "markdown",
                    "checksum": "3e0a4f6601c7f14255a9e6e33da79643",
                    "grade": true,
                    "grade_id": "cell-e7e33002d7f98b1c",
                    "locked": false,
                    "points": 2,
                    "schema_version": 3,
                    "solution": true
                }
            },
            "source": [
                "YOUR ANSWER HERE"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "cell_type": "markdown",
                    "checksum": "e25e4226e69d57f16851edaaea94da05",
                    "grade": false,
                    "grade_id": "cell-bb7d9bfa4b989e94",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false
                }
            },
            "source": [
                "So, for the mean, we get $\\textit{standard error} = \\frac{\\textit{standard deviation}}{\\sqrt{\\textit{n}}}$... probably some of you remember this from statistics class."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}